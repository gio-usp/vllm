{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install mistralai anthropic langdetect"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qlwPizylSx6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S6ay__78in3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "from google.genai import Client as GenaiClient\n",
        "from openai import OpenAI as OpenAIClient\n",
        "from mistralai import Mistral as MistralClient\n",
        "from anthropic import Anthropic as AnthropicClient\n",
        "from huggingface_hub import InferenceClient as HFClient\n",
        "from typing import TypedDict\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import json\n",
        "from uuid import uuid4\n",
        "import datetime\n",
        "from enum import Enum\n",
        "import nltk\n",
        "import langdetect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_MOUNT_PATH = '/content/drive'\n",
        "PROJECT_ROOT = f'{DRIVE_MOUNT_PATH}/MyDrive/ifeval'\n",
        "LIB_DIR = '/instruction_following_eval'\n",
        "INPUT_FILEPATH = f'{PROJECT_ROOT}{LIB_DIR}/data/input_data.jsonl'\n",
        "OUTPUT_DIR = f'{PROJECT_ROOT}{LIB_DIR}/data/output/'\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "0whmofBxATB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485f9d6b-5df2-4f3d-8ca9-ef5313f8987a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GENAI_API_KEY = userdata.get('GENAI_API_KEY')\n",
        "MISTRAL_API_KEY = userdata.get('MISTRAL_API_KEY')\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "2jxaSAc2XPww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "drive.mount(DRIVE_MOUNT_PATH)"
      ],
      "metadata": {
        "id": "SN2RCi2AHc1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd {DRIVE_MOUNT_PATH}{PROJECT_ROOT}"
      ],
      "metadata": {
        "id": "Ustt-s0o_ldc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -r instruction_following_eval/requirements.txt"
      ],
      "metadata": {
        "id": "QKP5IY_v806K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "with open(INPUT_FILEPATH, 'r') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            questions.append(json.loads(line).get('prompt'))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Skipping invalid JSON line: {line.strip()} - Error: {e}\", file=sys.stderr)\n",
        "            continue"
      ],
      "metadata": {
        "id": "a8UYPQbMdxlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatMessage(TypedDict):\n",
        "    role: str\n",
        "    content: str\n",
        "\n",
        "Chat = list[ChatMessage]\n",
        "\n",
        "class ProviderID(Enum):\n",
        "  OPENAI = 'openai'\n",
        "  GOOGLE = 'google'\n",
        "  ANTHROPIC = 'anthropic'\n",
        "  MISTRAL = 'mistral'\n",
        "  HF = 'hf'\n",
        "\n",
        "class BatchStatus(Enum):\n",
        "  CREATED = 'created'\n",
        "  PENDING = 'pending'\n",
        "  RUNNING = 'running'\n",
        "  COMPLETED = 'completed'\n",
        "  FAILED = 'failed'\n",
        "  CANCELED = 'canceled'\n",
        "  UNEXISTING = 'unexisting'\n",
        "\n",
        "class InferenceMode(Enum):\n",
        "  COMPLETIONS = 'completions'\n",
        "  RESPONSES = 'responses'\n",
        "\n",
        "class ModelClient:\n",
        "\n",
        "  def __init__(self, id: str, provider_client, hyperparameters: dict = None):\n",
        "    self.id: str = id\n",
        "    self.provider_client: OpenAIClient = provider_client\n",
        "    self.hyperparameters: dict = hyperparameters if hyperparameters else dict()\n",
        "\n",
        "  def get_completion(self, messages: list[Chat]):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def get_response(self, question: str, instruction: str = None):\n",
        "    raise NotImplementedError(self)\n",
        "\n",
        "  def create_batch(self, model_id: str, questions: list):\n",
        "    raise NotImplementedError(self)\n",
        "\n",
        "  def get_batch_by_id(self, batch_id: str):\n",
        "    raise NotImplementedError(self)\n",
        "\n",
        "  def retrieve_batch_result(self, batch_id: str):\n",
        "    raise NotImplementedError(self)\n",
        "\n",
        "  def create_batch_file(self, questions: list, batch_id: str = None):\n",
        "    raise NotImplementedError(self)\n",
        "\n",
        "  def cancel_batch(self, batch_id: str):\n",
        "    raise NotImplementedError(self)\n",
        "\n",
        "class OpenAIModelClient(ModelClient):\n",
        "\n",
        "  def __init__(self, id: str, provider_client: OpenAIClient, hyperparameters: dict = None):\n",
        "    super().__init__(id, provider_client, hyperparameters)\n",
        "\n",
        "  def get_completion(self, messages: list[Chat]):\n",
        "    return self.provider_client.chat.completions.create(\n",
        "      model=self.id,\n",
        "      messages=messages\n",
        "    ).choices[0].message.content\n",
        "\n",
        "  def get_response(self, question: str, instruction: str = None):\n",
        "    return self.provider_client.responses.create(\n",
        "      model=self.id,\n",
        "      instructions=instruction,\n",
        "      input=question\n",
        "    ).output_text\n",
        "\n",
        "  def create_batch_file(self, questions: list, batch_id: str = None):\n",
        "    if not questions:\n",
        "      raise ValueError(\"Questions cannot be empty\")\n",
        "    if isinstance(questions[0], str):\n",
        "      questions = [[{'role': 'user', 'content': question}] for question in questions]\n",
        "    id = batch_id if batch_id else f\"batch-{str(uuid4())[-8:]}\"\n",
        "    interim_filename = f\"{OUTPUT_DIR}{id}.jsonl\"\n",
        "    with open(interim_filename, 'w') as f_iter:\n",
        "      for i, question in enumerate(questions):\n",
        "        f_iter.write(json.dumps({\"custom_id\": f\"{id}-{i}\",\n",
        "                            \"method\": \"POST\",\n",
        "                            \"url\": f\"/v1/chat/completions\",\n",
        "                            \"body\": {\"model\": self.id,\n",
        "                                    \"messages\": question}\n",
        "\n",
        "                            }))\n",
        "        f_iter.write('\\n')\n",
        "\n",
        "    interim_resp = self.provider_client.files.create(\n",
        "      file=open(interim_filename, \"rb\"),\n",
        "      purpose=\"batch\"\n",
        "    )\n",
        "\n",
        "    if interim_resp and 0 < interim_resp.bytes == os.path.getsize(interim_filename):\n",
        "      os.remove(interim_filename)\n",
        "      return interim_resp.id\n",
        "    else:\n",
        "      raise Exception(f\"Wrong upload file size \\\"{interim_filename}\\\" has {interim_resp['bytes']}\")\n",
        "\n",
        "  def create_batch(self, batch_file_id: str):\n",
        "\n",
        "    if not batch_file_id:\n",
        "      raise ValueError(\"Batch file id cannot be empty\")\n",
        "\n",
        "    return self.provider_client.batches.create(\n",
        "      input_file_id=batch_file_id,\n",
        "      completion_window='24h',\n",
        "      endpoint=f\"/v1/chat/completions\",\n",
        "    ), batch_file_id\n",
        "\n",
        "  def get_batch_by_id(self, batch_id: str):\n",
        "    return self.provider_client.batches.retrieve(batch_id)\n",
        "\n",
        "  def retrieve_batch_result(self, batch_id: str):\n",
        "    batch = self.get_batch_by_id(batch_id)\n",
        "    if not batch.output_file_id:\n",
        "      return None\n",
        "    ret = []\n",
        "    with open(f\"{OUTPUT_DIR}output-{self.id}-{batch_id}.jsonl\", 'w') as f:\n",
        "      for i, line in enumerate(p.get_models()['gpt-4o-mini'].provider_client.files.content(batch.output_file_id).text.strip().split(\"\\n\")):\n",
        "        if not line:\n",
        "          continue\n",
        "        f.write(\n",
        "            json.dumps({\n",
        "                'prompt': questions[i],\n",
        "                'response': json.dumps(json.loads(line).get('response').get('body').get('choices')[0].get('message').get('content'))\n",
        "            })\n",
        "        )\n",
        "        f.write('\\n')\n",
        "      ret.append(f\"{OUTPUT_DIR}{batch_id}.jsonl\")\n",
        "    return ret\n",
        "\n",
        "\n",
        "  def cancel_batch(self, batch_id: str):\n",
        "    return self.provider_client.batches.cancel(batch_id)\n",
        "\n",
        "\n",
        "class HFModelClient(ModelClient):\n",
        "\n",
        "  def __init__(self, id: str, provider_client: HFClient, hyperparameters: dict = None):\n",
        "    super().__init__(id, provider_client, hyperparameters)\n",
        "\n",
        "  def create_batch(self, model_id: str, questions: list):\n",
        "    raise NotImplementedError(self)\n",
        "\n",
        "class MistralAIClient(OpenAIClient):\n",
        "\n",
        "  def __init__(*args, **kwargs):\n",
        "\n",
        "    super().__init__(*args, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "class Provider:\n",
        "\n",
        "  def __init__(self, id: ProviderID, cls: type, api_key: str, cls_args: dict = None):\n",
        "    self.id: str = id\n",
        "    self.cls: type = cls\n",
        "    self.api_key: str = api_key\n",
        "    self.cls_args: dict = cls_args if cls_args else dict()\n",
        "    self.client = None\n",
        "    self.models: list[str] = None\n",
        "\n",
        "  def get_client(self):\n",
        "    if not self.client:\n",
        "      self.client = self._get_client()\n",
        "    return self.client\n",
        "\n",
        "  def get_models(self):\n",
        "    if not self.models:\n",
        "      self.models = self._get_models()\n",
        "    return self.models\n",
        "\n",
        "  def _get_client(self):\n",
        "    return self.cls(api_key=self.api_key, **self.cls_args)\n",
        "\n",
        "  def _get_models(self):\n",
        "    raise NotImplementedError(self)\n",
        "\n",
        "class OpenAIProvider(Provider):\n",
        "\n",
        "  def __init__(self, api_key: str):\n",
        "    super().__init__(ProviderID.OPENAI, OpenAIClient, api_key)\n",
        "\n",
        "  def _get_models(self):\n",
        "    return dict(map(lambda x: (x.id, OpenAIModelClient(x.id, self.get_client(), dict())), self.get_client().models.list().data))"
      ],
      "metadata": {
        "id": "KfC9pYBwiVu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gWON1zQ0ti8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = OpenAIProvider(OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "qszkeTb7ijhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.get_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4wy6uJZXVbHs",
        "outputId": "0208456b-0b3a-4277-e3aa-0d136ff94455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gpt-4o-realtime-preview-2024-12-17': <__main__.OpenAIModelClient at 0x7855c0ccf650>,\n",
              " 'gpt-4o-audio-preview-2024-12-17': <__main__.OpenAIModelClient at 0x7855c091da90>,\n",
              " 'dall-e-3': <__main__.OpenAIModelClient at 0x7855c3913dd0>,\n",
              " 'dall-e-2': <__main__.OpenAIModelClient at 0x7855ccbc4310>,\n",
              " 'gpt-4o-audio-preview-2024-10-01': <__main__.OpenAIModelClient at 0x7855c0951990>,\n",
              " 'gpt-4-turbo-preview': <__main__.OpenAIModelClient at 0x7855c09533d0>,\n",
              " 'text-embedding-3-small': <__main__.OpenAIModelClient at 0x7855c0939390>,\n",
              " 'babbage-002': <__main__.OpenAIModelClient at 0x7855c0939450>,\n",
              " 'o1-mini-2024-09-12': <__main__.OpenAIModelClient at 0x7855c0939810>,\n",
              " 'o1-mini': <__main__.OpenAIModelClient at 0x7855c0939a50>,\n",
              " 'gpt-4': <__main__.OpenAIModelClient at 0x7855c0cbb6d0>,\n",
              " 'text-embedding-ada-002': <__main__.OpenAIModelClient at 0x7855c0c87750>,\n",
              " 'chatgpt-4o-latest': <__main__.OpenAIModelClient at 0x7855c090c210>,\n",
              " 'text-embedding-3-large': <__main__.OpenAIModelClient at 0x7855c090c290>,\n",
              " 'gpt-4o-mini-audio-preview': <__main__.OpenAIModelClient at 0x7855c090c2d0>,\n",
              " 'gpt-4o-audio-preview': <__main__.OpenAIModelClient at 0x7855c090c350>,\n",
              " 'o1-preview-2024-09-12': <__main__.OpenAIModelClient at 0x7855c090c3d0>,\n",
              " 'gpt-4o-mini-realtime-preview': <__main__.OpenAIModelClient at 0x7855c090c450>,\n",
              " 'gpt-4o-mini-realtime-preview-2024-12-17': <__main__.OpenAIModelClient at 0x7855c090c4d0>,\n",
              " 'gpt-3.5-turbo-instruct-0914': <__main__.OpenAIModelClient at 0x7855c090c550>,\n",
              " 'gpt-4o-mini-search-preview': <__main__.OpenAIModelClient at 0x7855c090c5d0>,\n",
              " 'o1': <__main__.OpenAIModelClient at 0x7855c090c650>,\n",
              " 'gpt-3.5-turbo-16k': <__main__.OpenAIModelClient at 0x7855c090c6d0>,\n",
              " 'o1-2024-12-17': <__main__.OpenAIModelClient at 0x7855c090c750>,\n",
              " 'gpt-4o-realtime-preview': <__main__.OpenAIModelClient at 0x7855c090c810>,\n",
              " 'davinci-002': <__main__.OpenAIModelClient at 0x7855c090c890>,\n",
              " 'gpt-3.5-turbo-1106': <__main__.OpenAIModelClient at 0x7855c090c910>,\n",
              " 'gpt-4o-search-preview': <__main__.OpenAIModelClient at 0x7855c090c990>,\n",
              " 'gpt-3.5-turbo-instruct': <__main__.OpenAIModelClient at 0x7855c090ca10>,\n",
              " 'gpt-3.5-turbo': <__main__.OpenAIModelClient at 0x7855c090ca90>,\n",
              " 'gpt-4o-mini-search-preview-2025-03-11': <__main__.OpenAIModelClient at 0x7855c090cb10>,\n",
              " 'gpt-4-0125-preview': <__main__.OpenAIModelClient at 0x7855c090cb90>,\n",
              " 'gpt-4o-2024-11-20': <__main__.OpenAIModelClient at 0x7855c090cc10>,\n",
              " 'gpt-4o-2024-05-13': <__main__.OpenAIModelClient at 0x7855c090cc90>,\n",
              " 'o1-pro': <__main__.OpenAIModelClient at 0x7855c090cd10>,\n",
              " 'o1-pro-2025-03-19': <__main__.OpenAIModelClient at 0x7855c090cd90>,\n",
              " 'o1-preview': <__main__.OpenAIModelClient at 0x7855c090ce10>,\n",
              " 'gpt-4-1106-preview': <__main__.OpenAIModelClient at 0x7855c090ce90>,\n",
              " 'gpt-4-0613': <__main__.OpenAIModelClient at 0x7855c090cf10>,\n",
              " 'gpt-4o-mini-tts': <__main__.OpenAIModelClient at 0x7855c090cf90>,\n",
              " 'gpt-4o-transcribe': <__main__.OpenAIModelClient at 0x7855c090d010>,\n",
              " 'gpt-4.5-preview': <__main__.OpenAIModelClient at 0x7855c090d090>,\n",
              " 'gpt-4.5-preview-2025-02-27': <__main__.OpenAIModelClient at 0x7855c090d110>,\n",
              " 'gpt-4o-search-preview-2025-03-11': <__main__.OpenAIModelClient at 0x7855c090d190>,\n",
              " 'omni-moderation-2024-09-26': <__main__.OpenAIModelClient at 0x7855c090d210>,\n",
              " 'o3-mini': <__main__.OpenAIModelClient at 0x7855c090d290>,\n",
              " 'o3-mini-2025-01-31': <__main__.OpenAIModelClient at 0x7855c090d310>,\n",
              " 'gpt-image-1': <__main__.OpenAIModelClient at 0x7855c090d390>,\n",
              " 'tts-1-hd': <__main__.OpenAIModelClient at 0x7855c090d410>,\n",
              " 'gpt-4o': <__main__.OpenAIModelClient at 0x7855c090d490>,\n",
              " 'tts-1-hd-1106': <__main__.OpenAIModelClient at 0x7855c090d510>,\n",
              " 'gpt-4o-2024-08-06': <__main__.OpenAIModelClient at 0x7855c090d590>,\n",
              " 'gpt-4o-mini-2024-07-18': <__main__.OpenAIModelClient at 0x7855c090d610>,\n",
              " 'gpt-4.1-mini': <__main__.OpenAIModelClient at 0x7855c090d690>,\n",
              " 'gpt-4o-mini': <__main__.OpenAIModelClient at 0x7855c090d710>,\n",
              " 'gpt-4o-mini-audio-preview-2024-12-17': <__main__.OpenAIModelClient at 0x7855c090d790>,\n",
              " 'gpt-3.5-turbo-0125': <__main__.OpenAIModelClient at 0x7855c090d810>,\n",
              " 'gpt-4-turbo': <__main__.OpenAIModelClient at 0x7855c090d890>,\n",
              " 'tts-1': <__main__.OpenAIModelClient at 0x7855c090d910>,\n",
              " 'gpt-4-turbo-2024-04-09': <__main__.OpenAIModelClient at 0x7855c090d990>,\n",
              " 'tts-1-1106': <__main__.OpenAIModelClient at 0x7855c090da10>,\n",
              " 'gpt-4o-realtime-preview-2024-10-01': <__main__.OpenAIModelClient at 0x7855c090da90>,\n",
              " 'gpt-4o-mini-transcribe': <__main__.OpenAIModelClient at 0x7855c090db10>,\n",
              " 'gpt-4.1-mini-2025-04-14': <__main__.OpenAIModelClient at 0x7855c090db90>,\n",
              " 'gpt-4.1': <__main__.OpenAIModelClient at 0x7855c090dc10>,\n",
              " 'whisper-1': <__main__.OpenAIModelClient at 0x7855c090dc90>,\n",
              " 'gpt-4.1-2025-04-14': <__main__.OpenAIModelClient at 0x7855c090dd10>,\n",
              " 'gpt-4.1-nano-2025-04-14': <__main__.OpenAIModelClient at 0x7855c090dd90>,\n",
              " 'omni-moderation-latest': <__main__.OpenAIModelClient at 0x7855c090de10>,\n",
              " 'o4-mini-2025-04-16': <__main__.OpenAIModelClient at 0x7855c090de90>,\n",
              " 'o4-mini': <__main__.OpenAIModelClient at 0x7855c090df10>,\n",
              " 'gpt-4.1-nano': <__main__.OpenAIModelClient at 0x7855c090df90>,\n",
              " 'ft:gpt-4o-mini-2024-07-18:personal:week-46-cif:BWWS610q:ckpt-step-211': <__main__.OpenAIModelClient at 0x7855c090e010>,\n",
              " 'ft:gpt-4o-mini-2024-07-18:personal:week-46-cif:BWWS65sI:ckpt-step-422': <__main__.OpenAIModelClient at 0x7855c090e090>,\n",
              " 'ft:gpt-4o-mini-2024-07-18:personal:week-46-cif:BWWS7Ka7': <__main__.OpenAIModelClient at 0x7855c090e110>,\n",
              " 'ft:gpt-3.5-turbo-0125:personal:week-46-cif:BWWYGBgE:ckpt-step-211': <__main__.OpenAIModelClient at 0x7855c090e190>,\n",
              " 'ft:gpt-3.5-turbo-0125:personal:week-46-cif:BWWYH4w3:ckpt-step-422': <__main__.OpenAIModelClient at 0x7855c090e210>,\n",
              " 'ft:gpt-3.5-turbo-0125:personal:week-46-cif:BWWYHfUp': <__main__.OpenAIModelClient at 0x7855c090e290>,\n",
              " 'ft:gpt-4o-2024-08-06:personal:week-46-cif:BWcVvpUg:ckpt-step-422': <__main__.OpenAIModelClient at 0x7855c090e310>,\n",
              " 'ft:gpt-4o-2024-08-06:personal:week-46-cif:BWcVvioZ': <__main__.OpenAIModelClient at 0x7855c090e390>,\n",
              " 'ft:gpt-4o-2024-08-06:personal:week-46-cif:BWcVucqH:ckpt-step-211': <__main__.OpenAIModelClient at 0x7855c090e410>}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_MODEL_IDS = ['ft:gpt-4o-mini-2024-07-18:personal:week-46-cif:BWWS7Ka7']"
      ],
      "metadata": {
        "id": "pWT2FLHlLMrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_batch_result(batch_id: str, model_id: str, tuned: bool):\n",
        "  with open(f\"{PROJECT_ROOT}/input-response-{model_id}-{'it' if tuned else 'pt'}.raw.jsonl\", 'w') as f:\n",
        "    with open(f'{PROJECT_ROOT}/instruction_following_eval/data/input-response{model_id}-{\"it\" if tuned else \"pt\"}.raw.jsonl','r') as fin:\n",
        "      for i, line in enumerate(fin):\n",
        "             f.write(\n",
        "                json.dumps({\n",
        "                    'prompt': questions[i],\n",
        "                    'response': json.loads(line).get('response').get('body').get('choices')[0].get('message').get('content')\n",
        "                }))\n",
        "             f.write('\\n')"
      ],
      "metadata": {
        "id": "Vxxh_ueF9-MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.get_models()['gpt-4o-mini'].get_completion([{'role': 'user', 'content': 'Ehere is Bragança Pta?'}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "ENmsPPUKipWz",
        "outputId": "5ce3655b-0a9a-48b0-af25-cd2907ad9a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bragança Paulista, often referred to simply as Bragança, is a municipality located in the state of São Paulo, Brazil. It is situated about 90 kilometers (approximately 56 miles) northwest of the city of São Paulo. Bragança Paulista is known for its lakes, green areas, and a mix of rural and urban environments. The city has historical and cultural significance, as well as various attractions for visitors. If you need more specific information about Bragança Paulista, feel free to ask!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.get_models()['gpt-4o-mini'].get_response('Where is Bragança Pta?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "DUIoClmSsNhy",
        "outputId": "fc3d0973-926f-47c7-9744-ed35505b6918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bragança Pta, also known as Bragança Paulista, is a municipality located in the state of São Paulo, Brazil. It is situated approximately 90 kilometers (about 56 miles) northeast of the city of São Paulo. The city is known for its historical buildings, natural beauty, and cultural events. If you need more specific information about Bragança Pta, feel free to ask!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bid, fid = p.get_models()['gpt-3.5-turbo-0125'].create_batch('file-NFXqKXAyLSjUkR7NWcx3BR')"
      ],
      "metadata": {
        "id": "2T1r_EHCCtxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bid, fid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjGmsdJxHf4B",
        "outputId": "3b0f46d1-38ed-47b4-f20b-7a51153eec56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Batch(id='batch_68227b46392c8190bf3c49daebfb4ffd', completion_window='24h', created_at=1747090246, endpoint='/v1/chat/completions', input_file_id='file-NFXqKXAyLSjUkR7NWcx3BR', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1747176646, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)),\n",
              " 'file-NFXqKXAyLSjUkR7NWcx3BR')"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.get_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H35telXyrdUQ",
        "outputId": "cd197f4c-1155-461d-c9cd-2bb204816709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gpt-4o-realtime-preview-2024-12-17': <__main__.OpenAIModelClient at 0x7d9451daf8d0>,\n",
              " 'gpt-4o-audio-preview-2024-12-17': <__main__.OpenAIModelClient at 0x7d9451949690>,\n",
              " 'dall-e-3': <__main__.OpenAIModelClient at 0x7d9451948c90>,\n",
              " 'dall-e-2': <__main__.OpenAIModelClient at 0x7d945194a510>,\n",
              " 'gpt-4o-audio-preview-2024-10-01': <__main__.OpenAIModelClient at 0x7d9451f798d0>,\n",
              " 'gpt-4-turbo-preview': <__main__.OpenAIModelClient at 0x7d9451b22ad0>,\n",
              " 'text-embedding-3-small': <__main__.OpenAIModelClient at 0x7d9451b22950>,\n",
              " 'babbage-002': <__main__.OpenAIModelClient at 0x7d9451b21310>,\n",
              " 'o1-mini-2024-09-12': <__main__.OpenAIModelClient at 0x7d9451b20590>,\n",
              " 'o1-mini': <__main__.OpenAIModelClient at 0x7d9451b200d0>,\n",
              " 'gpt-4': <__main__.OpenAIModelClient at 0x7d9451b23bd0>,\n",
              " 'text-embedding-ada-002': <__main__.OpenAIModelClient at 0x7d9451dc4dd0>,\n",
              " 'chatgpt-4o-latest': <__main__.OpenAIModelClient at 0x7d9451dc6050>,\n",
              " 'text-embedding-3-large': <__main__.OpenAIModelClient at 0x7d9451dc6b90>,\n",
              " 'gpt-4o-mini-audio-preview': <__main__.OpenAIModelClient at 0x7d9451dc5c90>,\n",
              " 'gpt-4o-audio-preview': <__main__.OpenAIModelClient at 0x7d9451dc45d0>,\n",
              " 'o1-preview-2024-09-12': <__main__.OpenAIModelClient at 0x7d9451dc7810>,\n",
              " 'gpt-4o-mini-realtime-preview': <__main__.OpenAIModelClient at 0x7d9451dc5750>,\n",
              " 'gpt-4o-mini-realtime-preview-2024-12-17': <__main__.OpenAIModelClient at 0x7d9451dc7110>,\n",
              " 'gpt-3.5-turbo-instruct-0914': <__main__.OpenAIModelClient at 0x7d9451dc5590>,\n",
              " 'gpt-4o-mini-search-preview': <__main__.OpenAIModelClient at 0x7d9451dc6f50>,\n",
              " 'o1': <__main__.OpenAIModelClient at 0x7d9451dc5890>,\n",
              " 'gpt-3.5-turbo-16k': <__main__.OpenAIModelClient at 0x7d9451dc7010>,\n",
              " 'o1-2024-12-17': <__main__.OpenAIModelClient at 0x7d9451dc7450>,\n",
              " 'gpt-4o-realtime-preview': <__main__.OpenAIModelClient at 0x7d9451dc7d50>,\n",
              " 'davinci-002': <__main__.OpenAIModelClient at 0x7d9451dc6110>,\n",
              " 'gpt-3.5-turbo-1106': <__main__.OpenAIModelClient at 0x7d9451dc5d90>,\n",
              " 'gpt-4o-search-preview': <__main__.OpenAIModelClient at 0x7d9451dc7510>,\n",
              " 'gpt-3.5-turbo-instruct': <__main__.OpenAIModelClient at 0x7d9451dc6c50>,\n",
              " 'gpt-3.5-turbo': <__main__.OpenAIModelClient at 0x7d9451dc5610>,\n",
              " 'gpt-4o-mini-search-preview-2025-03-11': <__main__.OpenAIModelClient at 0x7d9451dc4890>,\n",
              " 'gpt-4-0125-preview': <__main__.OpenAIModelClient at 0x7d9451dc6bd0>,\n",
              " 'gpt-4o-2024-11-20': <__main__.OpenAIModelClient at 0x7d9451dc6b50>,\n",
              " 'whisper-1': <__main__.OpenAIModelClient at 0x7d9451dc7d90>,\n",
              " 'gpt-4o-2024-05-13': <__main__.OpenAIModelClient at 0x7d9451dc5b10>,\n",
              " 'o1-pro': <__main__.OpenAIModelClient at 0x7d9451dc49d0>,\n",
              " 'o1-pro-2025-03-19': <__main__.OpenAIModelClient at 0x7d9451dc77d0>,\n",
              " 'o1-preview': <__main__.OpenAIModelClient at 0x7d9451dc73d0>,\n",
              " 'gpt-4-1106-preview': <__main__.OpenAIModelClient at 0x7d9451dc6e50>,\n",
              " 'gpt-4-0613': <__main__.OpenAIModelClient at 0x7d9451dc6250>,\n",
              " 'gpt-4o-mini-tts': <__main__.OpenAIModelClient at 0x7d9451dc6a90>,\n",
              " 'gpt-4o-transcribe': <__main__.OpenAIModelClient at 0x7d9451dc6c90>,\n",
              " 'gpt-4.5-preview': <__main__.OpenAIModelClient at 0x7d9451dc4610>,\n",
              " 'gpt-4.5-preview-2025-02-27': <__main__.OpenAIModelClient at 0x7d9451dc6fd0>,\n",
              " 'gpt-4o-search-preview-2025-03-11': <__main__.OpenAIModelClient at 0x7d9451dc7610>,\n",
              " 'omni-moderation-2024-09-26': <__main__.OpenAIModelClient at 0x7d9451dc4d50>,\n",
              " 'o3-mini': <__main__.OpenAIModelClient at 0x7d9451dc64d0>,\n",
              " 'o3-mini-2025-01-31': <__main__.OpenAIModelClient at 0x7d9451dc6e90>,\n",
              " 'gpt-image-1': <__main__.OpenAIModelClient at 0x7d9451dc6e10>,\n",
              " 'tts-1-hd': <__main__.OpenAIModelClient at 0x7d9451dc76d0>,\n",
              " 'gpt-4o': <__main__.OpenAIModelClient at 0x7d9451dc4b50>,\n",
              " 'tts-1-hd-1106': <__main__.OpenAIModelClient at 0x7d9451dc78d0>,\n",
              " 'gpt-4o-2024-08-06': <__main__.OpenAIModelClient at 0x7d9451dc7290>,\n",
              " 'gpt-4o-mini-2024-07-18': <__main__.OpenAIModelClient at 0x7d9451dc72d0>,\n",
              " 'gpt-4.1-mini': <__main__.OpenAIModelClient at 0x7d9451dc4950>,\n",
              " 'gpt-4o-mini': <__main__.OpenAIModelClient at 0x7d9451dc4cd0>,\n",
              " 'gpt-4o-mini-audio-preview-2024-12-17': <__main__.OpenAIModelClient at 0x7d9451dc51d0>,\n",
              " 'gpt-3.5-turbo-0125': <__main__.OpenAIModelClient at 0x7d9451dc69d0>,\n",
              " 'gpt-4-turbo': <__main__.OpenAIModelClient at 0x7d9451dc5e10>,\n",
              " 'tts-1': <__main__.OpenAIModelClient at 0x7d9451dc7fd0>,\n",
              " 'gpt-4-turbo-2024-04-09': <__main__.OpenAIModelClient at 0x7d9451dc6d90>,\n",
              " 'tts-1-1106': <__main__.OpenAIModelClient at 0x7d9451dc5f10>,\n",
              " 'gpt-4o-realtime-preview-2024-10-01': <__main__.OpenAIModelClient at 0x7d9451dc5b90>,\n",
              " 'gpt-4o-mini-transcribe': <__main__.OpenAIModelClient at 0x7d9451dc67d0>,\n",
              " 'gpt-4.1-mini-2025-04-14': <__main__.OpenAIModelClient at 0x7d9451dc4b10>,\n",
              " 'gpt-4.1': <__main__.OpenAIModelClient at 0x7d9451dc7ad0>,\n",
              " 'gpt-4.1-2025-04-14': <__main__.OpenAIModelClient at 0x7d9451dc4c10>,\n",
              " 'gpt-4.1-nano-2025-04-14': <__main__.OpenAIModelClient at 0x7d9451dc4a90>,\n",
              " 'omni-moderation-latest': <__main__.OpenAIModelClient at 0x7d9451dc5950>,\n",
              " 'o4-mini-2025-04-16': <__main__.OpenAIModelClient at 0x7d9451dc5390>,\n",
              " 'o4-mini': <__main__.OpenAIModelClient at 0x7d9451dc5ed0>,\n",
              " 'gpt-4.1-nano': <__main__.OpenAIModelClient at 0x7d9451dc7f50>}"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.get_models()['gpt-4o'].get_batch_by_id('batch_6822636e0ac88190a46a8d6876d4bd51')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBOaP95iHhPU",
        "outputId": "67943195-c7cf-40a0-94a6-9fc4a5d8037a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Batch(id='batch_6822636e0ac88190a46a8d6876d4bd51', completion_window='24h', created_at=1747084142, endpoint='/v1/chat/completions', input_file_id='file-NFXqKXAyLSjUkR7NWcx3BR', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1747170542, failed_at=None, finalizing_at=None, in_progress_at=1747084204, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=128, failed=0, total=541))"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.get_models()['gpt-4o-mini'].retrieve_batch_result(bid.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRP1IUVjPoEm",
        "outputId": "9d33c6a4-9d39-479c-906b-b3762227027e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/ifeval/instruction_following_eval/data/output/batch_68224476eae081908d8c545546d771da.jsonl']"
            ]
          },
          "metadata": {},
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bid,fid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVpoGLvLIMNh",
        "outputId": "f648307c-3d54-4ddd-8739-679a0032c724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Batch(id='batch_68222d24352c8190a6cc36e6ddf96a66', completion_window='24h', created_at=1747070244, endpoint='/v1/responses', input_file_id='file-FbduykPYRoUP8JpWNN24Qn', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1747156644, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)),\n",
              " 'file-FbduykPYRoUP8JpWNN24Qn')"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.get_models()['gpt-4o'].cancel_batch('batch_68222d24352c8190a6cc36e6ddf96a66')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvbdBGPPIOAj",
        "outputId": "baec5698-bc96-436a-f9f1-3f4453d402be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Batch(id='batch_68222d24352c8190a6cc36e6ddf96a66', completion_window='24h', created_at=1747070244, endpoint='/v1/responses', input_file_id='file-FbduykPYRoUP8JpWNN24Qn', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1747070857, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1747156644, failed_at=None, finalizing_at=None, in_progress_at=1747070306, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=491, total=541))"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MistralAIClient(api_key=MISTRAL_API_KEY).evals.run('eval_6823dcc9259c819099880608ddf54fad')"
      ],
      "metadata": {
        "id": "MGzTKquMBwQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cwd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOzHhn8DeZbY",
        "outputId": "666c3900-f108-491e-cf0c-fd45c1daa573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cwd: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m instruction_following_eval.evaluation_main \\\n",
        "  --input_data=/content/drive/MyDrive/ifeval/instruction_following_eval/data/input_data.jsonl \\\n",
        "  --input_response_data=/content/drive/MyDrive/ifeval/instruction_following_eval/data/input-response-4o-ifeval-pt.jsonl \\\n",
        "  --output_dir=/content/drive/MyDrive/ifeval/instruction_following_eval/data/output/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfMboyOUarTX",
        "outputId": "a1af005d-e554-4cb5-d41e-cedb16e4b489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'instruction_following_eval.evaluation_main' (ModuleNotFoundError: No module named 'instruction_following_eval')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " response->body->choices[0>message[0>content"
      ],
      "metadata": {
        "id": "9zY1iixlMyjo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hy40aLfT4-q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EulktNxghrHy",
        "outputId": "14155702-6256-437e-970d-ce30ce6e6cc0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.8.5.post1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.4)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.51.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.51.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.30.0->vllm) (0.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (4.25.7)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.12)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.78.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.4)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.11)\n",
            "Requirement already satisfied: llguidance<0.8.0,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.7.19)\n",
            "Requirement already satisfied: outlines==0.1.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.11)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.18 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.18)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.13.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1.1.post5)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (26.4.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n",
            "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.16.3)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.0.0)\n",
            "Requirement already satisfied: mistral_common>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.5.4->vllm) (1.5.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.9.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.3)\n",
            "Requirement already satisfied: depyf==0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.18.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.5)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\n",
            "Requirement already satisfied: opentelemetry-sdk<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-api<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.4.8)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.61.2)\n",
            "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.46.0)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0+cu124)\n",
            "Requirement already satisfied: xformers==0.0.29.post2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.29.post2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.3.7)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.2->vllm) (0.44.0)\n",
            "Requirement already satisfied: interegular in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
            "Requirement already satisfied: airportsdata in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (20250224)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->vllm) (1.3.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.7)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm) (24.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.2.18)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm) (0.47b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.4.26)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.1->vllm) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.3)\n",
            "Requirement already satisfied: rich-toolkit>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.14.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!HF_TOKEN={HF_TOKEN} vllm serve \"giovannioliveira/gemma-2-2B-it-w46-cif-sft\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPVziQclj8Ok",
        "outputId": "9af97e25-a44d-42bb-a612-22e5fe857705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: huggingface_hub: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6yvExJc5oIgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}